{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a5b54b-28ee-4492-adec-93b8e41863a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8656986-a150-44c3-bffc-2d019f393f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "from pyqtgraph.Qt import QtGui, QtCore\n",
    "import pyqtgraph as pg\n",
    "from face_utilities import Face_utilities\n",
    "from signal_processing import Signal_processing\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e669fc5-49a3-469e-ab8f-8c9fb8b4b35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c62621-c16d-4ca0-a08f-85a1de72ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29649bf-8b58-4466-98cb-9d04c1fa2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 15:50:04\n",
      "INFO:root:End of video. Total running time: 45.163917779922485\n",
      "INFO:root:We should have about 900 frames, and we have 860\n",
      "INFO:root:Final BPM: 145\n",
      "INFO:root:Average BPM: 69\n",
      "INFO:root:Real BPM: 100.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 15:53:33\n",
      "WARNING:root:No face detected\n",
      "WARNING:root:No face detected\n",
      "WARNING:root:No face detected\n",
      "INFO:root:End of video. Total running time: 49.042524337768555\n",
      "INFO:root:We should have about 900 frames, and we have 905\n",
      "INFO:root:Final BPM: 72\n",
      "INFO:root:Average BPM: 67\n",
      "INFO:root:Real BPM: 101.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 15:55:30\n",
      "WARNING:root:No face detected\n",
      "WARNING:root:No face detected\n",
      "INFO:root:End of video. Total running time: 50.97717094421387\n",
      "INFO:root:We should have about 900 frames, and we have 903\n",
      "INFO:root:Final BPM: 54\n",
      "INFO:root:Average BPM: 79\n",
      "INFO:root:Real BPM: 129.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 15:58:54\n",
      "INFO:root:End of video. Total running time: 48.956969261169434\n",
      "INFO:root:We should have about 900 frames, and we have 924\n",
      "INFO:root:Final BPM: 54\n",
      "INFO:root:Average BPM: 64\n",
      "INFO:root:Real BPM: 128.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 16:00:19\n",
      "INFO:root:End of video. Total running time: 47.290518045425415\n",
      "INFO:root:We should have about 900 frames, and we have 909\n",
      "INFO:root:Final BPM: 54\n",
      "INFO:root:Average BPM: 58\n",
      "INFO:root:Real BPM: 140.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 16:01:10\n",
      "INFO:root:End of video. Total running time: 47.84912109375\n",
      "INFO:root:We should have about 900 frames, and we have 894\n",
      "INFO:root:Final BPM: 72\n",
      "INFO:root:Average BPM: 60\n",
      "INFO:root:Real BPM: 143.0\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:\n",
      "Reading video 16:02:15\n",
      "/home/benitez/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/benitez/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfps: \u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fps), (\u001b[38;5;241m30\u001b[39m,\u001b[38;5;28mint\u001b[39m(frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.85\u001b[39m)), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m detrended_data \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_detrending\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m#print(len(detrended_data))\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#print(len(times))\u001b[39;00m\n\u001b[1;32m    109\u001b[0m interpolated_data \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39minterpolation(detrended_data, times)\n",
      "File \u001b[0;32m~/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/signal_processing.py:41\u001b[0m, in \u001b[0;36mSignal_processing.signal_detrending\u001b[0;34m(self, data_buffer)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_detrending\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_buffer):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    remove overall trending\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     detrended_data \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetrend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m detrended_data\n",
      "File \u001b[0;32m~/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/scipy/signal/_signaltools.py:3558\u001b[0m, in \u001b[0;36mdetrend\u001b[0;34m(data, axis, type, bp, overwrite_data)\u001b[0m\n\u001b[1;32m   3556\u001b[0m     A[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcast[dtype](np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, Npts \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m Npts)\n\u001b[1;32m   3557\u001b[0m     sl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(bp[m], bp[m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m-> 3558\u001b[0m     coef, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43msl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3559\u001b[0m     newdata[sl] \u001b[38;5;241m=\u001b[39m newdata[sl] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A, coef)\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;66;03m# Put data back in original shape.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/scipy/linalg/_basic.py:1156\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;124;03mCompute least-squares solution to equation Ax = b.\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m a1 \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n\u001b[0;32m-> 1156\u001b[0m b1 \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_validated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput array a should be 2D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/scipy/_lib/_util.py:252\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    251\u001b[0m toarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray_chkfinite \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray\n\u001b[0;32m--> 252\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/Semester temp/Class - BiomedicalSignals/labs/semester_project/heart-rate-from-camera/.venv/lib/python3.8/site-packages/numpy/lib/function_base.py:603\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    601\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"assets/data.csv\", index_col='N')\n",
    "data['HR_predicted'] = np.NaN\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isna(row['Recording']):\n",
    "        continue\n",
    "    #cap = cv2.VideoCapture(\"assets/video_3.mp4\")\n",
    "    logging.info('-'*50)\n",
    "    logging.info(f\"\\nReading video {index} ({row['Recording']})\")\n",
    "    cap = cv2.VideoCapture(f\"assets/video/{row['Recording']}.mp4\")\n",
    "\n",
    "    \n",
    "    fu = Face_utilities()\n",
    "    sp = Signal_processing()\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    #for signal_processing\n",
    "    BUFFER_SIZE = 100\n",
    "    \n",
    "    fps=0 #for real time capture\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS) # for video capture\n",
    "    #print(video_fps)\n",
    "    \n",
    "    times: list = []  # size: 1 x BUFFER_SIZE\n",
    "    data_buffer: list = []  # size: 1 x BUFFER_SIZE\n",
    "    data_buffer_all: list = []  # size: 1 x videoFrames\n",
    "    filtered_data = []  # size: 1 x BUFFER_SIZE\n",
    "    fft_of_interest = []\n",
    "    freqs_of_interest = []\n",
    "    \n",
    "    bpm = 0\n",
    "    bpm_all = []  # size: 1 x videoFrames\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        # grab a frame -> face detection -> crop the face -> 68 facial landmarks -> get mask from those landmarks\n",
    "        t0 = time.time()    \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if frame is None:\n",
    "            break\n",
    "        \n",
    "        ret_process = fu.no_age_gender_face_process(frame, \"68\")\n",
    "        \n",
    "        if ret_process is None:\n",
    "            logging.warning(\"No face detected\")\n",
    "            continue\n",
    "        \n",
    "        rects, face, shape, aligned_face, aligned_shape = ret_process\n",
    "        \n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "        if(len(aligned_shape)==68):\n",
    "            cv2.rectangle(aligned_face,(aligned_shape[54][0], aligned_shape[29][1]), #draw rectangle on right and left cheeks\n",
    "                    (aligned_shape[12][0],aligned_shape[33][1]), (0,255,0), 0)\n",
    "            cv2.rectangle(aligned_face, (aligned_shape[4][0], aligned_shape[29][1]), \n",
    "                    (aligned_shape[48][0],aligned_shape[33][1]), (0,255,0), 0)\n",
    "        else:\n",
    "            cv2.rectangle(aligned_face, (aligned_shape[0][0],int((aligned_shape[4][1] + aligned_shape[2][1])/2)),\n",
    "                        (aligned_shape[1][0],aligned_shape[4][1]), (0,255,0), 0)\n",
    "            \n",
    "            cv2.rectangle(aligned_face, (aligned_shape[2][0],int((aligned_shape[4][1] + aligned_shape[2][1])/2)),\n",
    "                        (aligned_shape[3][0],aligned_shape[4][1]), (0,255,0), 0)\n",
    "        \n",
    "        for (x, y) in aligned_shape: \n",
    "            cv2.circle(aligned_face, (x, y), 1, (0, 0, 255), -1)\n",
    "            \n",
    "            \n",
    "        #for signal_processing\n",
    "        ROIs = fu.ROI_extraction(aligned_face, aligned_shape)\n",
    "        green_val = sp.extract_color(ROIs)\n",
    "        logging.debug(green_val)\n",
    "        \n",
    "        data_buffer.append(green_val)\n",
    "        data_buffer_all.append(green_val)\n",
    "        \n",
    "        times.append((1.0/video_fps)*i)\n",
    "        \n",
    "        L = len(data_buffer)        \n",
    "        if L > BUFFER_SIZE:\n",
    "            data_buffer = data_buffer[-BUFFER_SIZE:]\n",
    "            times = times[-BUFFER_SIZE:]\n",
    "            L = BUFFER_SIZE\n",
    "            cv2.putText(frame, \"Filling up buffer...\", (30,int(frame.shape[0]*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        if L==100:\n",
    "            fps = float(L) / (times[-1] - times[0])\n",
    "            cv2.putText(frame, \"fps: {0:.2f}\".format(fps), (30,int(frame.shape[0]*0.85)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            detrended_data = sp.signal_detrending(data_buffer)\n",
    "            interpolated_data = sp.interpolation(detrended_data, times)\n",
    "            normalized_data = sp.normalization(interpolated_data)\n",
    "            \n",
    "            fft_of_interest, freqs_of_interest = sp.fft(normalized_data, fps)\n",
    "            max_arg = np.argmax(fft_of_interest)\n",
    "            bpm = freqs_of_interest[max_arg]\n",
    "            cv2.putText(frame, \"HR_real: {0:.2f}\".format(row['HR']), (30,int(frame.shape[0]*0.90)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(frame, \"HR_predicted: {0:.2f}\".format(bpm), (30,int(frame.shape[0]*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            filtered_data = sp.butter_bandpass_filter(interpolated_data, (bpm-20)/60, (bpm+20)/60, fps, order = 3)\n",
    "            \n",
    "        bpm_all.append(bpm)\n",
    "    \n",
    "        # display\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        cv2.imshow(\"face\",aligned_face)\n",
    "        i = i+1\n",
    "        logging.debug(\"time of the loop number \"+ str(i) +\" : \" + str(time.time()-t0))\n",
    "        \n",
    "        # waitKey to show the frame and break loop whenever 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    assert len(data_buffer) == 100\n",
    "    assert len(bpm_all) == len(data_buffer_all)\n",
    "    logging.info(\"End of video. Total running time: \" + str(time.time() - t))\n",
    "    logging.info(f\"We should have about {int(video_fps*30)} frames, and we have {len(bpm_all)}\")\n",
    "    logging.info(f\"Final BPM: {int(bpm_all[-1])}\")\n",
    "    logging.info(f\"Average BPM: {int(np.mean(bpm_all[BUFFER_SIZE:]))}\")\n",
    "    logging.info(f\"Real BPM: {row['HR']}\")\n",
    "\n",
    "    data.loc[index, 'HR_predicted'] = int(np.mean(bpm_all[BUFFER_SIZE:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e092cc-6497-4bc5-9608-60c0cb9473e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8a6f3-d7ca-4e6a-ad41-72885a4fa3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4666c-2bb8-4c1a-97f1-f2ad23842d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e7089-c3f0-4264-8fac-70b35092f356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cb4a2-e105-4408-ba0a-9efcb97b274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(bpm_all)\n",
    "plt.show()\n",
    "plt.plot(data_buffer_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
